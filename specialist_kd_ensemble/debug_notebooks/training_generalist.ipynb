{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-01T12:02:24.755185Z",
     "iopub.status.busy": "2022-07-01T12:02:24.754764Z",
     "iopub.status.idle": "2022-07-01T12:02:26.968842Z",
     "shell.execute_reply": "2022-07-01T12:02:26.966862Z",
     "shell.execute_reply.started": "2022-07-01T12:02:24.755107Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "import torchvision.models as models \n",
    "import torch.optim as optim \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:13:27.774420Z",
     "iopub.status.busy": "2022-07-01T12:13:27.774078Z",
     "iopub.status.idle": "2022-07-01T12:13:27.794617Z",
     "shell.execute_reply": "2022-07-01T12:13:27.793522Z",
     "shell.execute_reply.started": "2022-07-01T12:13:27.774391Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_scratch(trainloader, testloader, model, optimizer, scheduler, criterion, num_epochs, model_path, device): \n",
    "    lowest_test_loss = 1000.0 \n",
    "    for epoch in range(num_epochs): \n",
    "        running_loss, train_corrects, train_total = 0.0, 0, 0\n",
    "        model.train() \n",
    "        for inputs, labels in trainloader: \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            predicted_class = outputs.data.max(1, keepdim = True)[1]\n",
    "            train_corrects += predicted_class.eq(labels.data.view_as(predicted_class)).cpu().sum()\n",
    "            train_total += labels.size(0)\n",
    "    \n",
    "        # Evaluation \n",
    "        test_corrects, test_total, test_running_loss = evaluate(model, testloader, device)\n",
    "\n",
    "        scheduler.step()\n",
    "        if test_running_loss/test_total < lowest_test_loss: \n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            lowest_test_loss = test_running_loss/test_total\n",
    " \n",
    "        print(f'[{epoch + 1}], train_loss: {running_loss/train_total:.4f}, test_loss: {test_running_loss/test_total:.4f}, train_accuracy: {train_corrects*100/train_total:.2f} %, test_accuracy: {test_corrects*100/test_total:.2f} %')\n",
    "\n",
    "def evaluate(model, testloader, device):   \n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    test_running_loss, test_corrects, test_total = 0.0, 0, 0 \n",
    "    model.eval() \n",
    "    with torch.no_grad(): \n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device) \n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_running_loss += loss.item() \n",
    "            predicted_class = outputs.data.max(1, keepdim = True)[1]\n",
    "            test_corrects += predicted_class.eq(labels.data.view_as(predicted_class)).cpu().sum()\n",
    "            test_total += labels.size(0)\n",
    "\n",
    "    return test_corrects, test_total, test_running_loss\n",
    "\n",
    "def get_generalist_model(pretrained_generalist_path, trainloader, testloader): \n",
    "\n",
    "    generalist_model_name = 'cifar100_' + 'resnet20'\n",
    "    generalist_model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", generalist_model_name, pretrained = True)\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    generalist_model.to(device)\n",
    "    \n",
    "    if pretrained_generalist_path is None: \n",
    "        print(\"No pretrained path available. Training a new model as the generalist\")\n",
    "        optimizer = optim.SGD(generalist_model.parameters(), lr = 0.001, momentum = 0.9, nesterov = True, weight_decay = 5e-4)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.1)\n",
    "        criterion = nn.CrossEntropyLoss() \n",
    "        model_path = \"teacher_model_cifar100.pth\"\n",
    "        pretrained_generalist_path = model_path \n",
    "        num_epochs = 10 \n",
    "        train_and_evaluate_scratch(trainloader, testloader, generalist_model, optimizer, scheduler, criterion, num_epochs, model_path, device)\n",
    "    \n",
    "    generalist_state_dict = torch.load(pretrained_generalist_path, map_location = device)\n",
    "    generalist_model.load_state_dict(generalist_state_dict)\n",
    "    \n",
    "    return generalist_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T12:13:30.881567Z",
     "iopub.status.busy": "2022-07-01T12:13:30.881222Z",
     "iopub.status.idle": "2022-07-01T12:23:30.533091Z",
     "shell.execute_reply": "2022-07-01T12:23:30.531107Z",
     "shell.execute_reply.started": "2022-07-01T12:13:30.881535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\yeewenli/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrained path available. Training a new model as the generalist\n",
      "[1], train_loss: 0.0026, test_loss: 1.1691, train_accuracy: 90.96 %, test_accuracy: 68.60 %\n",
      "[2], train_loss: 0.0021, test_loss: 1.1714, train_accuracy: 93.13 %, test_accuracy: 68.72 %\n",
      "[3], train_loss: 0.0020, test_loss: 1.1802, train_accuracy: 94.07 %, test_accuracy: 68.68 %\n",
      "[4], train_loss: 0.0019, test_loss: 1.1843, train_accuracy: 94.71 %, test_accuracy: 68.62 %\n",
      "[5], train_loss: 0.0018, test_loss: 1.1840, train_accuracy: 95.27 %, test_accuracy: 68.45 %\n",
      "[6], train_loss: 0.0017, test_loss: 1.1960, train_accuracy: 95.73 %, test_accuracy: 68.37 %\n",
      "[7], train_loss: 0.0016, test_loss: 1.1967, train_accuracy: 95.94 %, test_accuracy: 68.48 %\n",
      "[8], train_loss: 0.0015, test_loss: 1.1977, train_accuracy: 96.48 %, test_accuracy: 68.08 %\n",
      "[9], train_loss: 0.0015, test_loss: 1.2068, train_accuracy: 96.69 %, test_accuracy: 68.17 %\n",
      "[10], train_loss: 0.0014, test_loss: 1.2207, train_accuracy: 97.02 %, test_accuracy: 67.92 %\n"
     ]
    }
   ],
   "source": [
    "transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
    "    \n",
    "trainset = torchvision.datasets.CIFAR100(root = './data', train = True, download = True, transform = transformation)\n",
    "testset = torchvision.datasets.CIFAR100(root = './data', train = False, download = True, transform = transformation)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 128, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 1, shuffle = False)\n",
    "\n",
    "generalist_model = get_generalist_model(None, trainloader, testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
