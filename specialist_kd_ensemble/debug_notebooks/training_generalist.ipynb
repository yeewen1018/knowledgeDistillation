{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision \nimport torchvision.transforms as transforms \nimport torchvision.models as models \nimport torch.optim as optim \nimport torch.nn as nn \nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-01T12:02:24.754764Z","iopub.execute_input":"2022-07-01T12:02:24.755185Z","iopub.status.idle":"2022-07-01T12:02:26.968842Z","shell.execute_reply.started":"2022-07-01T12:02:24.755107Z","shell.execute_reply":"2022-07-01T12:02:26.966862Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate_scratch(trainloader, testloader, model, optimizer, scheduler, criterion, num_epochs, model_path): \n    lowest_test_loss = 1000.0 \n    for epoch in range(num_epochs): \n        running_loss, train_corrects, train_total = 0.0, 0, 0\n        model.train() \n        for i, data in enumerate(trainloader, 0): \n            inputs, labels = data \n            if torch.cuda.is_available(): \n                inputs, labels = inputs.cuda(), labels.cuda()\n            \n            optimizer.zero_grad() \n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward() \n            optimizer.step()\n\n            running_loss += loss.item()\n            predicted_class = outputs.data.max(1, keepdim = True)[1]\n            train_corrects += predicted_class.eq(labels.data.view_as(predicted_class)).cpu().sum()\n            train_total += labels.size(0)\n    \n        # Evaluation \n        test_corrects, test_total, test_running_loss = evaluate(model, testloader)\n\n        scheduler.step()\n        if test_running_loss/test_total < lowest_test_loss: \n            torch.save(model.state_dict, model_path)\n            lowest_test_loss = test_running_loss/test_total\n \n        print('[{}], train_loss: {}, test_loss: {}, train_accuracy: {} %, test_accuracy: {} %'.format(epoch+1, running_loss/train_total, test_running_loss/test_total, \n        train_corrects*100/train_total, test_corrects*100/test_total))\n\n\ndef evaluate(model, testloader):   \n    criterion = nn.CrossEntropyLoss() \n    test_running_loss, test_corrects, test_total = 0.0, 0, 0 \n    model.eval() \n    with torch.no_grad(): \n        for data in testloader:\n            inputs, labels = data\n            if torch.cuda.is_available(): \n                inputs, labels = inputs.cuda(), labels.cuda()\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            test_running_loss += loss.item() \n            predicted_class = outputs.data.max(1, keepdim = True)[1]\n            test_corrects += predicted_class.eq(labels.data.view_as(predicted_class)).cpu().sum()\n            test_total += labels.size(0)\n\n    return test_corrects, test_total, test_running_loss\n\n\ndef get_generalist_model(pretrained_generalist_path, trainloader, testloader): \n\n    generalist_model_name = 'cifar100_' + 'resnet20'\n    generalist_model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", generalist_model_name, pretrained = True)\n\n    if pretrained_generalist_path is not None: \n        print(\"Using pre-trained generalist model\")\n        generalist_state_dict = torch.load(pretrained_generalist_path, map_location = torch.device('cpu'))\n        generalist_model.load_state_dict(generalist_state_dict)\n        if torch.cuda.is_available():\n            generalist_model = generalist_model.cuda()\n    else: \n        print(\"No pretrained path available. Training a new model as the generalist\")\n        if torch.cuda.is_available(): \n            generalist_model = generalist_model.cuda() \n        optimizer = optim.SGD(generalist_model.parameters(), lr = 0.001, momentum = 0.9, nesterov = True, weight_decay = 5e-4)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.1)\n        criterion = nn.CrossEntropyLoss() \n        model_path = 'teacher_model_cifar100.pth'\n        train_and_evaluate_scratch(trainloader, testloader, generalist_model, optimizer, scheduler, criterion, 10, model_path)\n    \n    return generalist_model ","metadata":{"execution":{"iopub.status.busy":"2022-07-01T12:13:27.774078Z","iopub.execute_input":"2022-07-01T12:13:27.774420Z","iopub.status.idle":"2022-07-01T12:13:27.794617Z","shell.execute_reply.started":"2022-07-01T12:13:27.774391Z","shell.execute_reply":"2022-07-01T12:13:27.793522Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n    \ntrainset = torchvision.datasets.CIFAR100(root = './data', train = True, download = True, transform = transformation)\ntestset = torchvision.datasets.CIFAR100(root = './data', train = False, download = True, transform = transformation)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size = 128, shuffle = True)\ntestloader = torch.utils.data.DataLoader(testset, batch_size = 1, shuffle = False)\n\ngeneralist_model = get_generalist_model(None, trainloader, testloader)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T12:13:30.881222Z","iopub.execute_input":"2022-07-01T12:13:30.881567Z","iopub.status.idle":"2022-07-01T12:23:30.533091Z","shell.execute_reply.started":"2022-07-01T12:13:30.881535Z","shell.execute_reply":"2022-07-01T12:23:30.531107Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"name":"stdout","text":"No pretrained path available. Training a new model as the generalist\n[1], train_loss: 0.0025461179679632188, test_loss: 1.1700654629195906, train_accuracy: 91.08200073242188 %, test_accuracy: 69.02999877929688 %\n[2], train_loss: 0.0021299282842874526, test_loss: 1.174413313458801, train_accuracy: 93.16400146484375 %, test_accuracy: 68.51000213623047 %\n[3], train_loss: 0.0019759627851843836, test_loss: 1.1756201090892617, train_accuracy: 93.97000122070312 %, test_accuracy: 68.56999969482422 %\n[4], train_loss: 0.001867857117652893, test_loss: 1.1808805552328463, train_accuracy: 94.6259994506836 %, test_accuracy: 68.51000213623047 %\n[5], train_loss: 0.0017691494822502135, test_loss: 1.1918881003540096, train_accuracy: 95.1520004272461 %, test_accuracy: 68.45999908447266 %\n[6], train_loss: 0.0016891899898648262, test_loss: 1.1948901089004291, train_accuracy: 95.6780014038086 %, test_accuracy: 68.37000274658203 %\n[7], train_loss: 0.0016106324490904808, test_loss: 1.200008534161732, train_accuracy: 95.97599792480469 %, test_accuracy: 68.2699966430664 %\n[8], train_loss: 0.0015363389113545417, test_loss: 1.206332871630586, train_accuracy: 96.43399810791016 %, test_accuracy: 68.0 %\n[9], train_loss: 0.0014689781168103217, test_loss: 1.2219216184286694, train_accuracy: 96.86599731445312 %, test_accuracy: 68.02999877929688 %\n[10], train_loss: 0.0014127840439975262, test_loss: 1.2189032022617936, train_accuracy: 96.99199676513672 %, test_accuracy: 68.37000274658203 %\n","output_type":"stream"}]}]}